# JSON Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨Ïö© Î™®Îìà
import json

import ipdb
# ÌÉÄÏûÖ ÌûåÌä∏Î•º ÏúÑÌïú Î™®Îìà
from typing import Dict
# Î¨¥ÏûëÏúÑ Ïàò ÏÉùÏÑ±ÏùÑ ÏúÑÌïú Î™®Îìà
import random
# tqdm: Î∞òÎ≥µÎ¨∏Ïùò ÏßÑÌñâ ÏÉÅÌô©ÏùÑ Î≥¥Ïó¨Ï£ºÎäî ÎùºÏù¥Î∏åÎü¨Î¶¨
from tqdm import trange, tqdm
import ast
# LLM Ï∂úÎ†• Í≤∞Í≥ºÎ•º ÌôïÏù∏ÌïòÎäî Ìï®Ïàò
from ..utils.llm_output_check import parse_list
# ÎèÑÍµ¨ Îì±Î°ù Î∞è Ï¥àÍ∏∞Ìôî Ìï®Ïàò
from ..base import register_tool, init_tool_instance
# ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏Îì§ Î∂àÎü¨Ïò§Í∏∞
from ..prompts_en2 import question_asker_system, expert_system, \
    dlg_based_writer_system, dlg_based_writer_prompt, chapter_writer_system

from mm_story_agent.base import register_tool
from mm_story_agent.modality_agents.LLMqwen import QwenAgent  # QwenAgent Î∂àÎü¨Ïò§Í∏∞
from mm_story_agent.modality_agents.LLMexaone import ExaoneAgent  # ExaoneAgent Î∂àÎü¨Ïò§Í∏∞

#Ï†ÑÏ≤¥ Ïù¥ÏïºÍ∏∞ ÏÉùÏÑ± ÌååÏù¥ÌîÑ ÎùºÏù∏Ïùò Ï§ëÏã¨ ÌÅ¥ÎûòÏä§ MMStoryAgentÎ•º Ï†ïÏùòÌïòÍ≥† Ïã§ÌñâÌïòÎäî Í≤É
from mm_story_agent.prompts_en2 import (
    scene_expert_system,
    scene_amateur_questioner_system,
    scene_refined_output_system,
    role_extract_system,
    role_review_system,
)

# JSON ÌòïÌÉúÏùò outlineÏù¥ Ïú†Ìö®ÌïúÏßÄ Í≤ÄÏÇ¨ÌïòÎäî Ìï®Ïàò
def json_parse_outline(outline):
    # ÏΩîÎìú Î∏îÎ°ù ÎßàÌÅ¨Îã§Ïö¥(```json Îì±)ÏùÑ Ï†úÍ±∞
    outline = outline.strip("```json").strip("```")
    try:
        # Î¨∏ÏûêÏó¥ÏùÑ JSONÏúºÎ°ú ÌååÏã±
        outline = json.loads(outline)
        # ÎîïÏÖîÎÑàÎ¶¨Ïù∏ÏßÄ ÌôïÏù∏
        if not isinstance(outline, dict):
            return False
        # ÌïÑÏöîÌïú ÌÇ§Îßå Ìè¨Ìï®ÎêòÏñ¥ ÏûàÎäîÏßÄ ÌôïÏù∏
        if outline.keys() != {"story_title", "story_outline"}:
            return False
        # Í∞Å Ï±ïÌÑ∞Í∞Ä ÌïÑÏöîÌïú ÌÇ§Î•º Í∞ÄÏßÄÍ≥† ÏûàÎäîÏßÄ ÌôïÏù∏
        for chapter in outline["story_outline"]:
            if chapter.keys() != {"chapter_title", "chapter_summary"}:
                return False
    except json.decoder.JSONDecodeError:
        # JSON ÌååÏã± Ïã§Ìå®
        return False
    return True  # Î™®Îì† Ï°∞Í±¥ ÌÜµÍ≥º Ïãú True Î∞òÌôò

# ÏßàÎ¨∏ ÏÉùÏÑ± LLM Í≥º Ï†ÑÎ¨∏Í∞Ä Ïó≠Ìï† LLMÏùÑ ÌÜµÌï¥ Q & A ÎåÄÌôî ÏÉùÏÑ± 
@register_tool("qa_outline_story_writer")
class QAOutlineStoryWriter:


    # ÌÅ¥ÎûòÏä§ ÏÉùÏÑ±Ïûê
    def __init__(self, cfg: Dict):
        self.cfg = cfg
        # LLM ÏÉùÏÑ± Ïò®ÎèÑ ÏÑ§Ï†ï (Í∏∞Î≥∏Í∞í 1.0)
        self.temperature = cfg.get("temperature", 1.0)
        # ÎåÄÌôî ÏµúÎåÄ ÌÑ¥ Ïàò ÏÑ§Ï†ï
        self.max_conv_turns = cfg.get("max_conv_turns", 3)
        # ÏÉùÏÑ±Ìï† ÏïÑÏõÉÎùºÏù∏ Í∞úÏàò ÏÑ§Ï†ï
        self.num_outline = cfg.get("num_outline", 4)
        # ÏÇ¨Ïö©Ìï† LLM Ï¢ÖÎ•ò ÏÑ§Ï†ï
        self.llm_type = cfg.get("llm", "qwen")

    # ÎåÄÌôî Í∏∞Î∞ò ÏïÑÏõÉÎùºÏù∏ÏùÑ JSON ÌòïÌÉúÎ°ú ÏÉùÏÑ±ÌïòÎäî Ìï®Ïàò
    def generate_outline(self, params):
        # params: Ïù¥ÏïºÍ∏∞ ÏÑ§Ï†ï Ï†ïÎ≥¥ (Ïòà: Ï†úÎ™©, Ï£ºÏù∏Í≥µ Îì±)

        # ÏßàÎ¨∏ ÏÉùÏÑ±Ïö© LLM Ï¥àÍ∏∞Ìôî
        asker = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": question_asker_system,
                "track_history": False
            }
        })

        # Ï†ÑÎ¨∏Í∞Ä Ïó≠Ìï† LLM Ï¥àÍ∏∞Ìôî
        expert = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": expert_system,
                "track_history": False
            }
        })

        # ÏßàÎ¨∏-ÎãµÎ≥Ä Í∏∞Î°ù Ï†ÄÏû• Î¶¨Ïä§Ìä∏
        dialogue = []
        for turn in trange(self.max_conv_turns):  # ÏµúÎåÄ ÏßÄÏ†ïÎêú ÌöüÏàòÎßåÌÅº Î∞òÎ≥µ
            dialogue_history = "\n".join(dialogue)  # ÌòÑÏû¨ÍπåÏßÄ ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨ Í≤∞Ìï©

            # Î≥ÄÍ≤Ω
            full_context = params.get("full_context", str(params))
            # ÏßàÎ¨∏ ÏÉùÏÑ±
            question, success = asker.call(
                f"Story setting: {full_context}\nDialogue history: \n{dialogue_history}\n",
                temperature=self.temperature
            )
            question = question.strip()

            # 'ÎåÄÌôî Ï¢ÖÎ£å' Î¨∏Íµ¨Í∞Ä ÎÇòÏò§Î©¥ Ï¢ÖÎ£å
            if question == "Thank you for your help!":
                break

            # ÏßàÎ¨∏ÏùÑ ÎåÄÌôî Í∏∞Î°ùÏóê Ï∂îÍ∞Ä
            dialogue.append(f"You: {question}")

            # Ï†ÑÎ¨∏Í∞ÄÏùò ÎãµÎ≥Ä ÏÉùÏÑ±
            answer, success = expert.call(
                f"Story setting: {full_context}\nQuestion: \n{question}\nAnswer: ",
                temperature=self.temperature
            )
            answer = answer.strip()
            dialogue.append(f"Expert: {answer}")

        # ÏïÑÏõÉÎùºÏù∏ ÏûëÏÑ±Í∏∞ LLM Ï¥àÍ∏∞Ìôî
        writer = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": dlg_based_writer_system,
                "track_history": False
            }
        })
        # full_context Í∞ÄÏ†∏Ïò§Í∏∞
        full_context = params.get("full_context", "")
        # ÏïÑÏõÉÎùºÏù∏ ÏûëÏÑ±Ïö© ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±
        writer_prompt = dlg_based_writer_prompt.format(
            story_setting=full_context,
            dialogue_history="\n".join(dialogue),
            num_outline=self.num_outline
        )

        # ÏïÑÏõÉÎùºÏù∏ ÏÉùÏÑ± ÏãúÎèÑ
        outline, success = writer.call(writer_prompt, success_check_fn=json_parse_outline)

        # ÎîîÎ≤ÑÍπÖÏö© Ï∂úÎ†•
        try:
            preview_outline = outline.replace("```json", "").replace("```", "").strip()
            parsed_outline = json.loads(preview_outline)
            print("üîç [DEBUG] Parsed Outline:")
            print(json.dumps(parsed_outline, ensure_ascii=False, indent=4))
        except Exception as e:
            print("‚ùå JSON ÌååÏã± Ïã§Ìå®. ÏõêÎ≥∏ Ï∂úÎ†•:")
            print(repr(outline))
        # Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ Í≤∞Í≥ºÏù∏ Í≤ΩÏö∞ ÏóêÎü¨ Î∞úÏÉù
        if not outline or not outline.strip():
            raise ValueError(f"LLMÏóêÏÑú Ïú†Ìö®Ìïú outlineÏùÑ Î∞õÏßÄ Î™ªÌñàÏäµÎãàÎã§: {repr(outline)}")

        # ÎßàÌÅ¨Îã§Ïö¥ JSON Î∏îÎ°ù Ï†úÍ±∞
        outline = outline.replace("```json", "").replace("```", "").strip()

        # JSON ÌååÏã±
        outline = json.loads(outline)

        # ÏµúÏ¢Ö outline Î∞òÌôò
        return outline

    # ÏïÑÏõÉÎùºÏù∏ÏùÑ Í∏∞Î∞òÏúºÎ°ú Ï±ïÌÑ∞Î≥Ñ ÏÉÅÏÑ∏ Ïù¥ÏïºÍ∏∞ ÏÉùÏÑ±
    def generate_story_from_outline(self, outline):
        # Ï±ïÌÑ∞ ÏûëÏÑ±Ïö© LLM Ï¥àÍ∏∞Ìôî
        chapter_writer = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": chapter_writer_system,
                "track_history": False
            }
        })

        all_pages = []  # Ï†ÑÏ≤¥ Ïù¥ÏïºÍ∏∞ ÌéòÏù¥ÏßÄ Î¶¨Ïä§Ìä∏
        for idx, chapter in enumerate(tqdm(outline["story_outline"])):
            # ÌòÑÏû¨ÍπåÏßÄÏùò ÎÇ¥Ïö©Í≥º ÏÉàÎ°úÏö¥ Ï±ïÌÑ∞ Ï†ïÎ≥¥Î•º ÏûÖÎ†•ÏúºÎ°ú Ï†ÑÎã¨
            chapter_detail, success = chapter_writer.call(
                json.dumps(
                    {
                        "completed_story": all_pages,
                        "current_chapter": chapter
                    },
                    ensure_ascii=False
                ),
                success_check_fn=parse_list,  # Ï∂úÎ†•Ïù¥ Î¶¨Ïä§Ìä∏ ÌòïÌÉúÏù∏ÏßÄ ÌôïÏù∏
                temperature=self.temperature
            )

            # Ïã§Ìå®Ìïú Í≤ΩÏö∞ ÏãúÎìú ÎûúÎç§Í∞í Ï£ºÏñ¥ Ïû¨ÏãúÎèÑ
            while success is False:
                chapter_detail, success = chapter_writer.call(
                    json.dumps(
                        {
                            "completed_story": all_pages,
                            "current_chapter": chapter
                        },
                        ensure_ascii=False
                    ),
                    seed=random.randint(0, 100000),  # ÏãúÎìú Î≥ÄÍ≤Ω
                    temperature=self.temperature,
                    success_check_fn=parse_list
                )

            # Î¨∏ÏûêÏó¥Î°ú Îêú Î¶¨Ïä§Ìä∏Î•º ÌååÏã± (eval ÏÇ¨Ïö©)
            pages = [page.strip() for page in eval(chapter_detail)]
            all_pages.extend(pages)  # Ï†ÑÏ≤¥ ÌéòÏù¥ÏßÄÏóê Ï∂îÍ∞Ä

        # Î™®Îì† ÌéòÏù¥ÏßÄ Î∞òÌôò
        return all_pages

    # Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ Ìï®Ïàò
    def call(self, params):
        # 1Îã®Í≥Ñ: ÏïÑÏõÉÎùºÏù∏ ÏÉùÏÑ±
        outline = self.generate_outline(params)
        # 2Îã®Í≥Ñ: ÏïÑÏõÉÎùºÏù∏ Í∏∞Î∞ò Ï±ïÌÑ∞Î≥Ñ Ïù¥ÏïºÍ∏∞ ÏÉùÏÑ±
        pages = self.generate_story_from_outline(outline)
        # ÏµúÏ¢Ö ÌéòÏù¥ÏßÄ Î¶¨Ïä§Ìä∏ Î∞òÌôò
        return pages
    

    # ÌÖçÏä§Ìä∏ Ï†ïÏ†ú Î∞è ÍµêÏ†ïÌïòÎäî Ïó≠Ìï† 

# @register_tool : Í∞Å ÏóêÏù¥Ï†ÑÌä∏Ïóê Ïù¥Î¶ÑÏùÑ Î∂ôÏó¨ÏÑú base.py Ïóê ÎèÑÍµ¨ Î†àÏßÄÏä§Ìä∏Î¶¨Ïóê Îì±Î°ù

# Ï†ïÏ†ú ÏóêÏù¥Ï†ÑÌä∏
@register_tool("RefineWriterAgent")
class RefineWriterAgent:
    # config ÏÑ§Ï†ï Ï†ïÎ≥¥ Î∞õÏïÑÏôÄÏÑú Ï¥àÍ∏∞Ìôî Î∞è LLM.pyÏùò Î™®Îç∏ÏùÑ Í∞ÄÏ†∏ÏôÄ Ï¥àÍ∏∞Ìôî
    def __init__(self, cfg):
        self.llm = ExaoneAgent(cfg)

    # ÏûÖÎ†•ÏúºÎ°ú Îì§Ïñ¥Ïò§Îäî ÎîïÏÖîÎÑàÎ¶¨ Î∞õÍ≥† "raw_text"ÎùºÎäî ÌÇ§Î•º ÌÜµÌï¥ Ï†ïÏ†úÌï† ÏõêÎ¨∏ Î∞õÍ∏∞
    def call(self, params):
        print("[RefineWriterAgent] Ï†ÑÏ≤¥ ÌÖçÏä§Ìä∏ Ï†ïÏ†ú Ï§ë")  
        prompt = params["raw_text"]
        response, _ = self.llm.call(prompt)
        print("[RefineWriterAgent] Ï†ÑÏ≤¥ ÌÖçÏä§Ìä∏ Ï†ïÏ†ú ÏôÑÎ£å.")  
        return response

# Ï†ÑÏ≤¥ Ïù¥ÏïºÍ∏∞Î•º Ïû•Î©¥ Îã®ÏúÑÎ°ú ÎÇòÎàî
# ÏûÖÎ†• : full_text / Ï≤òÎ¶¨ : LLMÏúºÎ°ú Ïû•Î©¥ÏùÑ Ï∂îÏ∂ú
# Î¶¨Ïä§Ìä∏ ÌòïÏãùÏù∏ÏßÄ ÌôïÏù∏ÌïòÎäî Ìï®Ïàò
def parse_list(output: str):
    try:
        parsed = ast.literal_eval(output)
        return isinstance(parsed, list)
    except Exception:
        return False

from tqdm import trange
import time  # optional: sleep() ÎÑ£Í≥† Ïã∂Îã§Î©¥ ÏÇ¨Ïö©

@register_tool("SceneExtractorAgent")
class SceneExtractorAgent:
    def __init__(self, cfg):
        self.cfg = cfg
        self.temperature = cfg.get("temperature", 0.7)
        self.max_conv_turns = cfg.get("max_conv_turns", 3)
        self.llm_type = cfg.get("llm", "qwen")

        # Í∞Å Ïó≠Ìï†Ïùò LLM Ï¥àÍ∏∞Ìôî
        print("[INFO] Ï†ÑÎ¨∏Í∞Ä LLM Ï¥àÍ∏∞Ìôî")
        self.expert = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": scene_expert_system,
                "track_history": False
            }
        })

        print("[INFO] ÏïÑÎßàÏ∂îÏñ¥ LLM Ï¥àÍ∏∞Ìôî")
        self.amateur = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": scene_amateur_questioner_system,
                "track_history": False
            }
        })

        print("[INFO] Ï†ïÏ†ú LLM Ï¥àÍ∏∞Ìôî")
        self.refiner = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": scene_refined_output_system,
                "track_history": False
            }
        })

    def call(self, params):
        full_text = params["full_text"]
        dialogue = []

        print("\n[STEP 1] Generating initial scene draft (Expert)...")
        initial_scene, _ = self.expert.call(full_text, temperature=self.temperature)
        print(">>> Initial Scene Draft:\n", initial_scene.strip(), "\n")
        dialogue.append(f"Expert: {initial_scene.strip()}")

        print("[STEP 2] Starting Q&A Refinement Loop...\n")
        for turn in trange(self.max_conv_turns, desc="Q&A Turns"):
            print(f"\n--- Turn {turn+1} ---")
            history = "\n".join(dialogue)

            question, _ = self.amateur.call(f"{full_text}\n{history}", temperature=self.temperature)
            print(f"[Amateur's Question]: {question.strip()}")
            dialogue.append(f"Amateur: {question.strip()}")

            answer, _ = self.expert.call(f"{full_text}\nQuestion: {question.strip()}", temperature=self.temperature)
            print(f"[Expert's Answer]: {answer.strip()}")
            dialogue.append(f"Expert: {answer.strip()}")

        print("\n[STEP 3] Refining final scene list...")
        final_prompt = "\n".join(dialogue)
        final_scene_list, success = self.refiner.call(
            f"{full_text}\n{final_prompt}",
            success_check_fn=parse_list,
            temperature=self.temperature
        )

        if not success:
            print("[ERROR] Scene extraction failed.")
            raise ValueError("Scene extraction failed.")

        print("\n‚úÖ Scene extraction complete. Final scene list:")
        ipdb.set_trace()
        print(final_scene_list)
        return eval(final_scene_list)

@register_tool("SummaryWriterAgent")
class SummaryWriterAgent:
    def __init__(self, cfg):
        self.llm = QwenAgent(cfg)
    def call(self, params):
        joined = "\n".join(params["scene_text"])
        response, _ = self.llm.call(f"Summarize the story: {joined}")
        return response

@register_tool("MetaWriterAgent")
class MetaWriterAgent:
    def __init__(self, cfg):
        self.llm = QwenAgent(cfg)
    def call(self, params):
        joined = "\n".join(params["scene_text"])
        response, _ = self.llm.call(f"Extract metadata (genre, tone, setting, themes, target age) from:\n{joined}")
        return response  # json ÌååÏã± ÏõêÌï† Í≤ΩÏö∞ Ï∂îÌõÑ Ï∂îÍ∞Ä
    
@register_tool("RoleExtractorAgent")
class RoleExtractorAgent:
    def __init__(self, cfg:Dict):
        self.cfg = cfg
        self.temperature = cfg.get("temperature", 1.0)
        self.max_conv_turns = cfg.get("max_conv_turns", 3)
        self.num_outline = cfg.get("num_outline", 4)
        self.qwenLlm = cfg.get("llm", "qwen")

    def extract_role_from_scene(self, scene_text):
        num_turns = self.cfg.get("num_turns", 3)
        role_extractor = init_tool_instance({
            "tool": self.cfg.get("llm", "qwen"),
            "cfg": {
                "system_prompt": role_extract_system,
                "track_history": False
            }
        })
        role_reviewer = init_tool_instance({
            "tool": self.cfg.get("llm", "qwen"),
            "cfg": {
                "system_prompt": role_review_system,
                "track_history": False
            }
        })
        roles = {}
        review = ""
        for turn in range(num_turns):
            roles, success = role_extractor.call(json.dumps({
                    "story_content": scene_text,
                    "previous_result": roles,
                    "improvement_suggestions": review,
                }, ensure_ascii=False
            ))
            roles = json.loads(roles.strip("```json").strip("```"))
            review, success = role_reviewer.call(json.dumps({
                "story_content": scene_text,
                "role_descriptions": roles
            }, ensure_ascii=False))
            if review == "Check passed.":
                break
        import ipdb
        ipdb.set_trace()
        return roles
    
@register_tool("ReferenceImagePromptWriterAgent")
class RefImgWriterAgent:
    def __init__(self, cfg:Dict):
        self.cfg = cfg
        self.temperature = cfg.get("temperature", 1.0)
        self.max_conv_turns = cfg.get("max_conv_turns", 3)
        self.num_outline = cfg.get("num_outline", 4)
        self.qwen = cfg.get("llm", "qwen")
        self.exaone = cfg.get("llm", "exaone")

    def generate_prompt_from_roles(self, roles:Dict[str,str]):
        refImgWriter = init_tool_instance({
            "tool": self.exaone,
            "cfg": {
                "system_prompt": "reference_image_write_system",
                "track_history": False
            }
        })

        input_data = {
            "characters": roles
        }

        input_str = json.dumps(input_data, ensure_ascii=False)

        prompt_text, success = refImgWriter.call(input_str)
        return prompt_text